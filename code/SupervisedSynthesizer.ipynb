{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.single_table import TVAESynthesizer\n",
    "from sdv.single_table import CopulaGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load data and create train test split from the smaller dataset that contains 10% of the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'adult'\n",
    "balanced = False\n",
    "target = 'income'\n",
    "prefix = ''\n",
    "optimization_itr = 50\n",
    "df_original = utilities.load_data(data_set_name, balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.2,  random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.loc[:, df_train.columns != target]\n",
    "y_train = df_train[target]\n",
    "\n",
    "x_test = df_test.loc[:, df_test.columns != target]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_original.copy()\n",
    "# df_modified = target_encoder.transform(df)\n",
    "\n",
    "# for col in cat_col:\n",
    "#     df[col] = df[col].astype('category')\n",
    "# df, df_te = train_test_split(df, test_size = 0.2,  random_state = 5)\n",
    "# df.to_csv(\"../data/train.csv\", index=False)\n",
    "# df_te.to_csv(\"../data/test.csv\", index=False)\n",
    "# target = 'income'\n",
    "\n",
    "# x_train = df.loc[:, df.columns != target]\n",
    "# y_train = df[target]\n",
    "\n",
    "# x_test = df_te.loc[:, df_te.columns != target]\n",
    "# y_test = df_te[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Supervised Synthesizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "        'eval_metric': 'auc'\n",
    "}\n",
    "def fit_synth(df, params):\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(data=df)\n",
    "    method = params['method']\n",
    "    if method == \"GaussianCopula\":\n",
    "        synth = GaussianCopulaSynthesizer(metadata=metadata)\n",
    "    elif method == \"CTGAN\" or method ==\"CopulaGAN\":\n",
    "        epoch = params['epochs']\n",
    "        batch_size = params['batch_size']*100\n",
    "        if params[\"g_dim3\"] != 0:\n",
    "            generator_dim = (128*params['g_dim1'], 128*params['g_dim2'], 128*params['g_dim3'])\n",
    "        else:\n",
    "            generator_dim = (128*params['g_dim1'], 128*params['g_dim2'])\n",
    "        if params[\"d_dim3\"] != 0:\n",
    "            discriminator_dim = (128*params['d_dim1'], 128*params['d_dim2'], 128*params['d_dim3'])\n",
    "        else:\n",
    "            discriminator_dim = (128*params['d_dim1'], 128*params['d_dim2'])\n",
    "        discriminator_lr = params['d_lr']\n",
    "        generator_lr = params['g_lr']\n",
    "        if method == \"CTGAN\":\n",
    "            synth = CTGANSynthesizer(metadata=metadata, epochs=epoch, batch_size=batch_size, generator_dim=generator_dim, \n",
    "                                     discriminator_dim=discriminator_dim, generator_lr=generator_lr, \n",
    "                                     discriminator_lr=discriminator_lr)\n",
    "        if method == \"CopulaGAN\":\n",
    "            synth = CopulaGANSynthesizer(metadata=metadata, epochs=epoch, batch_size=batch_size, generator_dim=generator_dim,\n",
    "                                         discriminator_dim=discriminator_dim, generator_lr=generator_lr,\n",
    "                                         discriminator_lr=discriminator_lr)\n",
    "    elif method == \"TVAE\":\n",
    "        epoch = params['epochs']\n",
    "        batch_size = params['batch_size']*100\n",
    "        if params[\"c_dim3\"] != 0:\n",
    "            compress_dims = (64*params['c_dim1'], 64*params['c_dim2'], 64*params['c_dim3'])\n",
    "        else:\n",
    "            compress_dims = (64*params['c_dim1'], 64*params['c_dim2'])\n",
    "        if params[\"d_dim3\"] != 0:\n",
    "            decompress_dims = (64*params['d_dim1'], 64*params['d_dim2'], 64*params['d_dim3'])\n",
    "        else:\n",
    "            decompress_dims = (64*params['d_dim1'], 64*params['d_dim2'])\n",
    "        synth = TVAESynthesizer(metadata=metadata, epochs=epoch, batch_size=batch_size, compress_dims=compress_dims, \n",
    "                                 decompress_dims=decompress_dims)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name: \" + method)\n",
    "    return synth\n",
    "\n",
    "def downstream_loss(sampled, df_te, target, classifier):\n",
    "    x_samp = sampled.loc[:, sampled.columns != target]\n",
    "    y_samp = sampled[target]\n",
    "    x_test = df_te.loc[:, sampled.columns != target]\n",
    "    y_test = df_te[target]\n",
    "    if classifier == \"XGB\":\n",
    "        for column in x_samp.columns:\n",
    "            if x_samp[column].dtype == 'object':\n",
    "                x_samp[column] = x_samp[column].astype('category')\n",
    "                x_test[column] = x_test[column].astype('category')\n",
    "        dtrain = xgb.DMatrix(data=x_samp, label=y_samp, enable_categorical=True)\n",
    "        dtest = xgb.DMatrix(data=x_test, label=y_test, enable_categorical=True)\n",
    "        clf = xgb.train(params_xgb, dtrain, 1000, verbose_eval=False)\n",
    "        clf_probs = clf.predict(dtest)\n",
    "        print(clf_probs)\n",
    "        clf_auc = roc_auc_score(y_test.values.astype(float), clf_probs)\n",
    "        return clf_auc\n",
    "    else:\n",
    "        raise ValueError(\"Invalid classifier: \" + classifier)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = 'CTGAN'\n",
    "params_range = {\n",
    "    'N_sim': 10000,\n",
    "    'target': 'income',\n",
    "    'loss': 'ROCAUC',\n",
    "    'method': method_name,\n",
    "    'epochs':  np.random.choice([100, 200, 300]),  \n",
    "    'batch_size':  hp.randint('batch_size',1, 5), # multiple of 100\n",
    "    'g_dim1':  hp.randint('g_dim1',1, 3), # multiple of 128\n",
    "    'g_dim2':  hp.randint('g_dim2',1, 3), # multiple of 128\n",
    "    'g_dim3':  hp.randint('g_dim3',0, 3), # multiple of 128\n",
    "    'd_dim1':  hp.randint('d_dim1',1, 3), # multiple of 128\n",
    "    'd_dim2':  hp.randint('d_dim2',1, 3), # multiple of 128\n",
    "    'd_dim3':  hp.randint('d_dim3',0, 3), # multiple of 128\n",
    "    'd_lr': np.random.choice([1e-4, 2e-4, 1e-3, 2e-3, 1e-2, 2e-2, 1e-1]),  \n",
    "    \"g_lr\": np.random.choice([1e-4, 2e-4, 1e-3, 2e-3, 1e-2, 2e-2, 1e-1]),\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_maximize(params):\n",
    "    global best_test_roc \n",
    "    global best_synth\n",
    "    synth = fit_synth(df_train, params)\n",
    "    synth.fit(df_train)\n",
    "    N_sim = params[\"N_sim\"]\n",
    "    sampled = synth.sample(num_rows = N_sim)\n",
    "    clf_auc = downstream_loss(sampled, df_test, target, classifier = \"XGB\")\n",
    "\n",
    "    if clf_auc > best_test_roc:\n",
    "        best_test_roc = clf_auc\n",
    "        best_synth = sampled\n",
    "    \n",
    "    return {\n",
    "        'loss' : 1 - clf_auc,\n",
    "        'status' : STATUS_OK,\n",
    "        'eval_time ': time.time(),\n",
    "        'test_roc' : clf_auc,\n",
    "        }\n",
    "\n",
    "\n",
    "def trainDT(max_evals:int):\n",
    "    global best_test_roc\n",
    "    global best_synth\n",
    "    \n",
    "    best_test_roc = 0\n",
    "    trials = Trials()\n",
    "    start = time.time()\n",
    "    clf_best_param = fmin(fn=objective_maximize,\n",
    "                    space=params_range,\n",
    "                    max_evals=max_evals,\n",
    "                   # rstate=np.random.default_rng(42),\n",
    "                    algo=tpe.suggest,\n",
    "                    trials=trials)\n",
    "    print(clf_best_param)\n",
    "    print('It takes %s minutes' % ((time.time() - start)/60))\n",
    "    return best_test_roc, best_synth, clf_best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_roc, best_synth, clf_best_param = trainDT(optimization_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best_param[\"test_roc\"] = best_test_roc\n",
    "pd.DataFrame.from_dict(clf_best_param).to_csv(\"../data/output/\" + prefix + data_set_name + \"_tuned_\" + method_name + \"_clf_best_param_xgboost.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_synth\n",
    "best_synth.to_csv(\"../data/output/\" + prefix + data_set_name + \"_tuned_\" + method_name + \"_synthetic_data_xgboost.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
